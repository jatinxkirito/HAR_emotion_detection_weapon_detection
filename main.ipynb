{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils #makes basix image processing resizing etc a lot easier\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "# pip install fer #if not already present\n",
    "from fer import FER\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras.utils.image_utils import  img_to_array\n",
    "from keras.applications import xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_lst=open(\"Actions.txt\").read().strip().split(\"\\n\")\n",
    "#getting labels for all possible activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "# loading the kinetic model\n",
    "md = cv2.dnn.readNet(\"resnet-34_kinetics.onnx\")\n",
    "face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "emotion=FER(mtcnn=True)\n",
    "weapon=tf.keras.models.load_model(\"weapon_detection.h5\")\n",
    "# accuracy above 90%\n",
    "fire=tf.keras.models.load_model(\"fd.h5\")\n",
    "# accuracy near 90%\n",
    "print(type(fire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_for_plant(image):\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_hsv = np.array([0,0,250])\n",
    "    upper_hsv = np.array([250,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "#image segmentation function\n",
    "def segment_image(image):\n",
    "    mask = create_mask_for_plant(image)\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return output/255\n",
    "\n",
    "#sharpen the image\n",
    "def sharpen_image(image):\n",
    "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
    "    return image_sharp\n",
    "\n",
    "def prepro(im):\n",
    "    img=im.copy()\n",
    "    img=cv2.resize(img,(255,255))\n",
    "    img=img_to_array(img)\n",
    "    image_segmented = segment_image(img)\n",
    "    #sharpen\n",
    "    image_sharpen = sharpen_image(image_segmented)\n",
    "    x = xception.preprocess_input(np.expand_dims(image_sharpen.copy(), axis=0))\n",
    "    return np.array(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpn(img):\n",
    "    m,n=50,50\n",
    "    im = img.copy()\n",
    "    \n",
    "    imrs = cv2.resize(img,(m,n))\n",
    "    #print(type(imrs))\n",
    "    imrs=img_to_array(imrs)/255\n",
    "    imrs=imrs.transpose(2,0,1)\n",
    "    imrs=imrs.reshape(3,m,n)\n",
    "    x=np.array([imrs])\n",
    "    predictions = weapon.predict(x)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for weapon detection\n",
    "label_names=sorted(['knife','no weapon'])\n",
    "def preprocess(imge, image_size = 300):\n",
    "    img=imge.copy()\n",
    "    image = cv2.resize(img, (image_size, image_size))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    # Expand dimensions as predict expect image in batches\n",
    "    image = np.expand_dims(image, axis=0) \n",
    "    return image\n",
    "def postprocess(img, results):\n",
    " \n",
    "    # Split the results into class probabilities and box coordinates\n",
    "    image=img.copy()\n",
    "    bounding_box, class_probs = results\n",
    "    class_index = np.argmax(class_probs)\n",
    "   \n",
    "    # Use this index to get the class name.\n",
    "    class_label=\"No Weapon\"\n",
    "    if(class_index==0):\n",
    "     class_label = \"Weapon\"\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    " \n",
    "    # Extract the Coordinates\n",
    "    x1, y1, x2, y2 = bounding_box[0]\n",
    " \n",
    "    # Convert the coordinates from relative (i.e. 0-1) to actual values\n",
    "    x1 = int(w * x1)\n",
    "    x2 = int(w * x2)\n",
    "    y1 = int(h * y1)\n",
    "    y2 = int(h * y2)\n",
    " \n",
    "    # return the lable and coordinates\n",
    "    return class_label, (x1,y1,x2,y2),class_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_bf = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "def fir(img):\n",
    "    im=img.copy()\n",
    "    im=prepro(im)\n",
    "    print(im.shape)\n",
    "    xception_bf = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "   # bf_train_x = xception_bf.predict(train_x, batch_size=32, verbose=1)\n",
    "    im = xception_bf.predict(im, batch_size=32, verbose=1)\n",
    "    prd=fire.predict(im)\n",
    "    return prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "cap=cv2.VideoCapture(0)\n",
    "to_process=[]\n",
    "original=[]\n",
    "label=\"None\"\n",
    "while True:\n",
    "\n",
    "    #now since we are video processing we would need continuous set of images instead of single frame by frame images we will need to convert it to blob \n",
    "    \n",
    "    # lets take 16 frames at a time to make blob\n",
    "   \n",
    "    bl,img=cap.read()\n",
    "    img=cv2.flip(img,1)\n",
    "   # cv2.imshow('wnd',img)\n",
    "    if bl==False:\n",
    "        print(\"Unable to get input. Exiting code\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    \n",
    "    x=imutils.resize(img,400)\n",
    "    to_process.append(x)\n",
    "    if(len(to_process)==16):\n",
    "        blob=cv2.dnn.blobFromImages(to_process,1.0,(112,112), (114.7748, 107.7354, 99.4750),swapRB=True, crop=True)\n",
    "        blob = np.transpose(blob, (1, 0, 2, 3))\n",
    "        blob = np.expand_dims(blob, axis=0)\n",
    "       # print(blob.shape)\n",
    "        md.setInput(blob)\n",
    "        ot=md.forward()\n",
    "        label=act_lst[np.argmax(ot)]\n",
    "        to_process.clear()\n",
    "\n",
    "   \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "    \n",
    "   \n",
    "   \n",
    "    cnt=(cnt%16)\n",
    "    s=\"None\"\n",
    "    # This part is commented out as my pc specs weren't good enough to compute multiple heavy models simultaneously\n",
    "    # if(cnt==0):\n",
    "    #     rt=fir(img)\n",
    "    \n",
    "    #     processed_image = preprocess(img)\n",
    "    #     results = weapon.predict(processed_image)\n",
    "\n",
    "    \n",
    "    #     labe, (x1, y1, x2, y2), confidence = postprocess(img, results)\n",
    "    #     if(labe==\"Weapon\"):\n",
    "    #         cv2.rectangle(img, (x1,y1), (x2,y2), (0, 0, 255), 2)\n",
    "    #         cv2.putText(\n",
    "    #             img, \n",
    "    #             '{}'.format(labe, confidence), \n",
    "    #             (x1, y1-10), \n",
    "    #             cv2.FONT_HERSHEY_COMPLEX, 0.9,\n",
    "    #             (0, 0, 255),2)\n",
    "    #     if(rt[0][0]<0.5):\n",
    "    #         cv2.putText(img,\"Fire\",(0,20),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),2)\n",
    "    \n",
    "    for (x, y, w, h) in faces_detected:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), thickness=7)\n",
    "        dominant_emotion, emotion_score = emotion.top_emotion(img)\n",
    "        cv2.putText(img, dominant_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.rectangle(img, (0, 0), (300, 40),\n",
    "                    (0, 0, 0), -1)\n",
    "    cv2.putText(img, label, (10, 25),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                (255, 255, 255), 2)\n",
    "    cv2.imshow('wnd',img)\n",
    "    cnt=cnt+1\n",
    "    if cv2.waitKey(1) & 0XFF==ord('a'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 255, 255, 3)\n",
      "1/1 [==============================] - 1s 629ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "#checking fire detection model on images\n",
    "img=cv2.imread('fire.101.png')\n",
    "rt=fir(img)\n",
    "if(rt[0][0]>0.5):\n",
    "    cv2.putText(img,\"No Fire\",(0,20),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),2)\n",
    "else:\n",
    "     cv2.putText(img,\"Fire\",(0,20),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),2)\n",
    "cv2.imshow(\"le\",img)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "Weapon\n"
     ]
    }
   ],
   "source": [
    "#checking knife detection on images\n",
    "img=cv2.imread('11.jpeg')\n",
    "processed_image = preprocess(img)\n",
    "results = weapon.predict(processed_image)\n",
    "\n",
    "labe, (x1, y1, x2, y2), confidence = postprocess(img, results)\n",
    "print(labe)\n",
    "cv2.rectangle(img, (x1,y1), (x2,y2), (0, 0, 255), 2)\n",
    "cv2.putText(\n",
    "    img, \n",
    "    '{}'.format(labe, confidence), \n",
    "    (x1, y1-10), \n",
    "    cv2.FONT_HERSHEY_COMPLEX, 0.9,\n",
    "    (0, 0, 255),2)\n",
    "cv2.imshow(\"le\",img)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
